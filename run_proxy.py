#!/usr/bin/env python
"""
å¯åŠ¨ LLM ä»£ç†æœåŠ¡
"""
import uvicorn
import sys
import os
import argparse

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.proxy.llm_proxy import app

if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="LLM API ä»£ç†æœåŠ¡")
    parser.add_argument(
        "--target-url", 
        default=os.getenv("TARGET_BASE_URL", "https://api.openai.com"),
        help="ç›®æ ‡ API çš„ base URL (é»˜è®¤: https://api.openai.com)"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8000,
        help="ä»£ç†æœåŠ¡ç«¯å£ (é»˜è®¤: 8000)"
    )
    args = parser.parse_args()
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["TARGET_BASE_URL"] = args.target_url
    
    print("ğŸš€ å¯åŠ¨ LLM ä»£ç†æœåŠ¡...", flush=True)
    print(f"ğŸ“¡ ä»£ç†åœ°å€: http://localhost:{args.port}", flush=True)
    print(f"ğŸ¯ ç›®æ ‡ API: {args.target_url}", flush=True)
    print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:", flush=True)
    print(f"   åœ¨å®¢æˆ·ç«¯è®¾ç½® API Base URL ä¸º: http://localhost:{args.port}/v1", flush=True)
    print("   ä¿æŒ API Key ä¸å˜\n", flush=True)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=args.port,
        log_level="info"
    ) 